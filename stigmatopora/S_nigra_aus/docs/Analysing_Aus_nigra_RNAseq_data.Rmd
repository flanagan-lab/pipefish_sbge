---
title: "Analysing Australian *Stigmatopora nigra* RNAseq Data"
author: "Emily Beasley"
date: "`r Sys.Date()`"
output: 
    html_document:
        code_folding: show
        toc: yes
        toc_float: yes
        number_sections: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir='../',fig_path="../imgs/")
```

``` {r library, include = FALSE}
#library(tximport) #This was used to generate an abundance matrix from the salmon quant outputs
```
This pipeline follows a pipeline outlined for _Syngnathus floridae_. Changes in scripts and outputs are outlined in this document. More detail about the programmes used can be found here:https://github.com/coley-tosto/PhD_thesis/blob/main/Chapter_3/docs/Analyzing_floridae_RNAseq_data_from_MSU.Rmd This pipeline was run on the University of Canterbury's RCC.

# Pre-assembly Quality Control and Filtering

## Trimming the Reads with Trimmomatic
[Trimmomatic](http://www.usadellab.org/cms/index.php?page=trimmomatic) is commonly used for Illumina paired-end and single ended data.  

### Running trimmomatic across Multiple Pairs of Reads

Trimmomatic was installed on the RCC through conda in a conda environment called **Trim**. Use command `conda activate Trim` before running Trimmomatic. 


```{bash}
#!/bin/bash

#Create the argument
input_dir=$1 #This should be the location of the RAW reads to be trimmed

for fq in $1*_R1_001.fastq.gz
        do
        base=$(basename $fq _R1_001.fastq.gz)
        echo "Running trimmomatic for ${base}..."
        time trimmomatic PE -threads 16 $fq $1${base}_R2_001.fastq.gz \
                $1trimmed/${base}_paired_R1_001.fastq.gz $1trimmed/${base}_unpaired_R1_001.fastq.gz \
                $1trimmed/${base}_paired_R2_001.fastq.gz $1trimmed/${base}_unpaired__R2_001.fastq.gz \
                HEADCROP:12 LEADING:3 TRAILING:10 SLIDINGWINDOW:4:15 MINLEN:50
done

```
-   Adapter content was removed prior to receiving the raw reads from Micromon, so the bash script `trim_no_adapter_run.sh` was used. If adapter content is present, use bash script `trimmomatic_run.sh`

-   Before running the script, change the `trimmomatic` line to `echo "..."` to make sure all of the variables are working correctly.

-   Trimmomatic takes about a day to run, so either run it with nohup or screen 

-   Then remove the `echo "..."` and run the script as `nohup bash ../scripts/trim_no_adapter_run.sh ../australia_nigra_raw_reads/ > trim.out 2>&1 &`.

## Using SortMeRNA to remove rRNA contamination
### Create a new environment and install SortMeRNA in it

SortMeRNA was installed in a conda environment as follows:

```
conda create -n sortmerna
conda activate sortmerna
conda install sortmerna

which sortmerna #check location of installation
  /home/rccuser/anaconda3/envs/contamination/bin/sortmerna
```

### Test the installation of SortMeRNA

```
sortmerna --version
    SortMeRNA version 4.3.6
    Build Date: Aug 16 2022
    sortmerna_build_git_sha:@db8c1983765f61986b46ee686734749eda235dcc@
    sortmerna_build_git_date:@2022/08/16 11:42:59@
```

### Download the latest SortMeRNA databases (v4.3.4)
The `database.tar.gz` file can also be downloaded from [this link](https://github.com/sortmerna/sortmerna/releases).

```
wget https://github.com/biocore/sortmerna/releases/download/v4.3.4/database.tar.gz
mkdir rRNA_databases_v4.3.4
tar -xvf database.tar.gz -C rRNA_databases_v4.3.4
```

### Run SortMeRNA - creating a for loop to run multiple samples at a time
```{bash, eval = FALSE}
#!/bin/bash

#Create arguments
input_dir=$1 #location of the reads
ref_fasta=$2 #desired reference fasta
output_dir_rrna=$3 #desired location for the reads that are rRNA
output_dir_norrna=$4 #desired location for the reads that are NOT rRNA

## Loop through all pairs of reads in the input directory
for pair in $1/*_R1_001.fastq.gz
        do

        #Extract the sample name from the file name
        sample=$(basename $pair _R1_001.fastq.gz)

        #Extract Fish ID
        ID=$(basename $pair _paired_R1_001.fastq.gz)

        ##Echo the sample name it is currently running
        echo "Running SortMeRNA for ${ID}..."

        #Define the paths to the input and output files for this sample
        input1=$1/${sample}_R1_001.fastq.gz
        input2=$1/${sample}_R2_001.fastq.gz

        #Run SortMeRNA on this pair of reads
        time sortmerna --threads 16 --ref $2 --reads $input1 --reads $input2 --fastx --aligned $3/${ID} --other $4/${ID} --out2

        #Remove SortMeRNA intermediate files before running again
        rm -r /home/rccuser/sortmerna/run/kvdb

done


```

This script was run as `nohup bash ../../scripts/sortmerna_run.sh paired/ /home/rccuser/shared/rRNA_databases_v4.3.4/smr_v4.3_fast_db.fasta rrna/ no_rrna/ > sortmerna.log 2>&1 &`

SortMeRNA takes 1-3 days to run depending on the number of samples you have. It took 2 days for these 16 paired samples.  

## Using Kraken2 to remove biological contamination

Kraken2 was installed in the conda environment `kraken2`

### Creating a for loop to run multiple samples at a time
```{bash, eval = FALSE}

#!/bin/bash

#Create arguments
ref_fasta=$1 #desired reference database
input_dir=$2 #Input directory with the location of the reads
output_dir=$3 #Desired location of the output

## Loop through all pairs of reads in the input directory
for pair in $2/*_fwd.fq.gz
        do

        #Extract the sample name from the file name
        sample=$(basename $pair _fwd.fq.gz)

        ##Echo the sample name it is currently running
        echo "Running Kraken2 for ${sample}..."

        #Define the paths to the input and output files for this sample
        input1=$2/${sample}_fwd.fq.gz
        input2=$2/${sample}_rev.fq.gz

        #Run Kraken2 on this pair of reads
        time kraken2 --threads 16 --db $1 --paired $input1 $input2 --unclassified-out $3/${sample}#.fq --report $3/${sample}.log

done

```


This script was run as `nohup bash ../../scripts/kraken2_run.sh /home/rccuser/shared/kraken2_pluspfp/ no_rrna/ kraken_output/ > kraken2.log 2>&1 &`

## Doing a k-mer based correction with RCorrector
Rcorrector (RNA-seq error CORRECTOR) is a kmer-based error correction method that is used on RNA-seq data. This program allows for a correction of random sequencing errors in Illumina RNA-seq reads. The downside is you may lose information on things like SNPs and other sequence variants.


### Creating a for loop to run multiple samples at a time
```{bash, eval = FALSE}
### Creating a for loop to run multiple samples at a time
#!/bin/bash

#Create arguments
rcorrector_path=$1 #Path to the run_rcorrector.pl file
input_dir=$2 #Path to the input directory containing the reads
output_dir=$3 #Path to the desired output location

##Loop through all pairs of reads in the directory
for pair in $2/*_1.fq
        do

        #Extract sample name from the file name
        sample=$(basename $pair _1.fq)

        #Echo the sample name that is currently running
        echo "Running rcorrector for ${sample} ..."

        #Run rcorrector on this pair of reads
        time perl $1/run_rcorrector.pl -t 16 -1 $2/${sample}_1.fq -2 $2/${sample}_2.fq -od $3

done

```

This script was run as `nohup bash ../../scripts/rcorrector_run.sh /home/rccuser/rcorrector/ kraken_output/ rcorrector/ > rcor.log 2>&1 &`

# Checking quality of trimmed and filtered reads
The quality of the reads once they finished going through the filtering and trimming pipeline outlined above was assessed with FastQC and the results were compiled using MultiQC.

1. **Trim** environment: Here is where the programs **Trimmomatic** and **fastqc** were installed.

2. **QC** environment: This is where **multiqc** was installed.

```{bash, eval = FALSE}
#!/bin/bash

input_dir=$1 #location of the reads
output_dir=$2 #name of the desired output directory

for fq in $1/*.cor.fq
        do
        base=$(basename $fq)
        echo "Running fastqc for ${base} ..."
        time fastqc $fq -t 16 -o $2
done

```

This script was run as `nohup bash ../../scripts/fastqc_run.sh rcorrector/ fastqc/ > fastqc.log 2>&1 &`. Once finished MultiQC was run: `multiqc fastqc`. 

# De novo transcriptome assembly

## Installing Trinity
Trinity requires the installation of several programs, to get around this Trinity was installed via a Docker in the RCC and must be used within one. **The first time that you use Trinity you must pull the latest Docker image for Trinity** like so:

```
docker pull trinityrnaseq/trinityrnaseq

```

## Running Trinity 
Once started, a successful Trinity run will take days to complete. There are a lot of extra components you can add onto a Trinity run (View the [Trinity User Manual](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-Trinity) for more information).
    
### Using multiple reads
#### Creating a Sample Name File
There are two options when using multiple files to generate your de novo transcriptome assembly. Each sample can be typed out individually, ensuring that the two reads are paired up by order. Alternatively, the argument `--samples_file` can be used instead. With this argument you must provide a tab-delimited text file indicating biological replicate relationships. This is the example provided on the [Trinity Website](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-Trinity):

         cond_A    cond_A_rep1    A_rep1_left.fq    A_rep1_right.fq
         cond_A    cond_A_rep2    A_rep2_left.fq    A_rep2_right.fq
         cond_B    cond_B_rep1    B_rep1_left.fq    B_rep1_right.fq
         cond_B    cond_B_rep2    B_rep2_left.fq    B_rep2_right.fq
         
The samples file that was provided for the script below was adapted into this format:

```
SNF11G	S1	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF11G_S1_L001_1.cor.fq	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF11G_S1_L001_2.cor.fq
SNF11L	S2	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF11L_S2_L001_1.cor.fq	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF11L_S2_L001_2.cor.fq
SNF11O	S3	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF11O_S3_L001_1.cor.fq /home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF11O_S3_L001_2.cor.fq
SNF12G	S4	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF12G_S4_L001_1.cor.fq	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF12G_S4_L001_2.cor.fq
SNF12L	S5	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF12L_S5_L001_1.cor.fq	/home/rccuser/shared/emily_files/australia_nigra_raw_reads/trimmed/rcorrector/SNF12L_S5_L001_2.cor.fq
...

```
The last two columns contain the **full** location to the desired reads.

#### Script
```{bash, eval = FALSE}
#!/bin/bash

#Create arguements
samples_file=$1 #File containing sample names and locations
out_dir_name=$2 #Desired name for the output directory

sudo docker run --rm -v`pwd`:`pwd` trinityrnaseq/trinityrnaseq Trinity --seqType fq --max_memory 188G \
        --samples_file $1 \
        --normalize_by_read_set \
        --CPU 16 \
        --output `pwd`/$2

```

Trinity was run inside of a **screen** session as `bash ../scripts/trinity_run.sh `pwd`/SNI_aus_samples.txt aus_nigra_trinity`. The `pwd` was added in front of the samples file name as a shortcut since Trinity needs to full path to the file (since it was installed as a docker image).

If you detatch from the **screen** session, you can resume the session using `screen -r`. 

