---
title: "Analyzing *Syngnathus floridae* RNAseq Data from MSU"
author: "Coley Tosto"
date: "`r Sys.Date()`"
output: 
    html_document:
        code_folding: show
        toc: yes
        toc_float: yes
        number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pre-assembly QUality Control and Filtering

## Trimming the Reads with Trimmomatic
[Trimmomatic](http://www.usadellab.org/cms/index.php?page=trimmomatic) is commonly used for Illumina paired-end and single ended data. There are a lot of different trimming steps that can be performed and parameters that correspond to each step. Currently for version **0.40** of trimmomatic these are the different steps:\
\

1.  **ILLUMINACLIP**: Cut adapter and other illumina-specific seuqences from the read.\
    `:<fastaWithAdaptersEtc>:<seed mismatches>:<palindrome clip threshold>:<simple clip threshold>`\
    -   fastaWithAdaptersEtc = specifies the path to a fasta file containing all the adapters, PCR sequences etc.
    -   seedMismatches = the max. mismatch count which will still allow a full match to be performed.
    -   palindromeClipThreshold = how accurate the match between the two 'adapter ligated' reads must be for PE palindrome read alignment
    -   simpleClipThreshold = how accurate the match between any adapterect. sequence must be against a read.
2.  **SLIDINGWINDOW**: Perform a sliding window trimming, cutting once the average quality within the window falls below a designated threshold.\
    `:<windowSize>:<requiredQuality>`\
    -   windowSize = the number of bases to average across
    -   requiredQuality = the average quality required
3.  **LEADING**: Cut bases off the start of a read, if below a designated threshold quality.\
    `:<quality>`\
    -   quality = the minimum quality required to keep a base
4.  **TRAILING**: Cut bases off the end of a read, if below a designated threshold quality.\
    `:<quality>`\
    -   quality = the minimum quality required to keep a base
5.  **CROP**: Cut the read to a specified length.\
    `:<length>`Â 
    -   length = the number of bases to keep, from the start of the read
6.  **HEADCROP**: Cut the specified number of bases from the start of a read.\
    `:<length>`\
    -   length = the number of bases to remove from the start of the read
7.  **MINLEN**: Drop the read if it is below a specified length.\
    `:<length>`
    -   length = the minimum length of reads to be kept

For **paired-end** data, two input files are specified and 4 output files. Two for the **paired** output where both of the reads survived the processing, and two for the corresponding **unpaired** output where one read survived but it's partner did not.\
\
**Trimming occurs in the order which the steps are specified on the command line**. Recommended that if the adapter clipping is required it is done as early as possible.

### Installing Trimmomatic

Trimmomatic was installed on the RCC through conda in a conda environment called **Trim**.

```
conda create -n Trim
conda activate Trim
conda install trimmomatic
```

### Running trimmomatic across Multiple Pairs of Reads

```{bash, eval=FALSE}
#!/bin/bash

data=/home/rccuser/20220902_mRNASeq_PE150/ ##This is the location of the raw reads

for fq in ${data}*_R1.fastq.gz
        do
        base=$(basename $fq _R1.fastq.gz)
        echo "Running trimmomatic for ${base}..."
        time trimmomatic PE -threads 16 $fq ${data}${base}_R2.fastq.gz \
                ${data}trimmed/${base}_paired_R1.fastq.gz ${data}trimmed/${base}_unpaired_R1.fastq.gz \    
                ${data}trimmed/${base}_paired_R2.fastq.gz ${data}trimmed/${base}_unpaired_R2.fastq.gz \    
                ILLUMINACLIP:NexteraPE-PE.fa:2:30:10 HEADCROP:12 LEADING:3 TRAILING:10 SLIDINGWINDOW:4:15 MINLEN:50
done
```

-   Before running the script, change the `trimmomatic` line to `echo "..."` to make sure all of the variables are working correctly.

-   Then remove the `echo ""` and run the script as `nohup bash trim_script.sh > trim.out 2>&1 &`.\

## Using Kraken2 to remove biological contamination
### Create a new environment and install Kraken2 in it

```
conda create -n kraken2
conda activate kraken2
conda install kraken2
```

### Creating the Standard Kraken2 Database {.tabset}
The Kraken2 Database can be generated in one of two ways

#### Builidng it by Hand {.unnumbered}
Kraken2 has a built in function `kraken2-build` that allows you to build whatever database you are wanting. For example if you want to generate the standard kraken2 database (That includes archea and bacteria):

```
mkdir kraken2_standard_db

kraken2-buid --standard --db kraken2_standard_db/
```

If you run into the following error:
"rsync_from_ncbi.pl: unexpected FTP path (new server?) for https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/900/128/725/GCF_900128725.1_BCifornacula_v1.0" 

You will need to change some of the code in the file `rsync_from_ncbi.pl`. If Kraken 2 was installed via conda the file will be located in `/anaconda3/envs/kraken2/share/kraken2-2.1.2-4/libexec`. Use `nano` to edit the file and on line **46** replace _ftp_ with _((ht|f)tp(s?))_ so the whole line for 46 would look like this:

`if (! ($full_path =~ s#^((ht|f)tp(s?))://${qm_server}${qm_server_path}/##)) {`


#### Uploading a pre-built database {.unnumbered}
This [website](https://benlangmead.github.io/aws-indexes/k2) also has all of the different datasets pre-built and available for download. To access one of these pre-built databases through the RCC directly use:

```
wget https://genome-idx.s3.amazonaws.com/kraken/k2_pluspfp_20230314.tar.gz #Using the link associated to the dataset of choice

mkdir kraken2_pluspfp_database
tar -xvf k2_pluspfp_20230314.tar.gz -C kraken2_pluspfp_database/
```

### Creating a for loop to run multiple samples at a time
```{bash, eval = FALSE}
#!/bin/bash

#Create arguments
ref_fasta=$1 #desired reference database
input_dir=$2 #Input directory with the location on the reads
output_dir=$3 #Desired location for the output

## Loop through all pairs of reads in the input directory
for pair in $2/*_R1.fq.gz
        do

        #Extract the sample name from the file name
        sample=$(basename $pair _R1.fq.gz)

        ##Echo the sample name it is currently running
        echo "Running Kraken2 for ${sample}..."

        #Define the paths to the input and output files for this sample
        input1=$2/${sample}_R1.fq.gz
        input2=$2/${sample}_R2.fq.gz

        #Run Kraken2 on this pair of reads
        time kraken2 --threads 16 --db $1 --paired $input1 $input2 --unclassified-out $3/${sample}#.fq --report $3/${sample}.log

done
```

This script was run as `nohup bash bash_scripts/kraken2.sh ../kraken2_pluspfp/ > kraken2.log 2>&1 &`

## Using SortMeRNA to remove rRNA contamination
### Create a new environment and install SortMeRNA in it

```
conda create -n sortmerna
conda activate sortmerna
conda install sortmerna

which sortmerna #check location of installation
  /home/rccuser/anaconda3/envs/contamination/bin/sortmerna
```

### Test the installation of SortMeRNA

```
sortmerna --version
    SortMeRNA version 4.3.6
    Build Date: Aug 16 2022
    sortmerna_build_git_sha:@db8c1983765f61986b46ee686734749eda235dcc@
    sortmerna_build_git_date:@2022/08/16 11:42:59@
```

### Download the latest SortMeRNA databases (v4.3.4)
The `database.tar.gz` file can also be downloaded from [this link](https://github.com/sortmerna/sortmerna/releases).

```
wget https://github.com/biocore/sortmerna/releases/download/v4.3.4/database.tar.gz
mkdir rRNA_databases_v4.3.4
tar -xvf database.tar.gz -C rRNA_databases_v4.3.4
```

These .fasta files are what will be used in the next step for our reference file. There are 4 fasta files associated with `v4.3.4`.

  1. `smr_v4.3_default_db.fasta`: this FASTA file contains the **default** SortMeRNA database, which is a comprehensive rRNA database derived from the SILVA and Rfam databases. This database includes Bacteria 16S/23S (SILVA), Archaea 16S (SILVA), Eukarya 18S/28S (SILVA),5S/5.8s rRNA (Rfam).
  
  2. `smr_v4.3_sensitive_db_rfam_seeds.fasta`: this FASTA file contatins **seed sequences** of the covariance models (CMs) from the Rfam database. Rfam is a comprehensive collection of RNA families, each represented by a CM that describes the consensus secondary structure of the RNA family. These CMs are used to annotate RNA sequences in genomes and metagenomes. The sensitivity of SortMeRNA can be increased by including this database in the analysis, but it can also increase the runtime and memory requirements of the analysis.
  
  3. `smr_v4.3_fast_db.fasta`: this FASTA file contains **a subset of sequences** from the default SortMeRNA database. Here, the number of sequences in each database is reduced to improve the speed of the analysis. This file would be intended for use in cases where speed is a priority and a lower sensitivity is acceptable.
  
  4. `smr_v4.3_sensitive_db.fasta`: this FASTA file contains **a more comprehensive set of sequences** than the default SortMeRNA database. The sensitive database is intended for use in cases where higher sensitivity is required, such as in metagenomic or environmental sequencing studies, but similar to the second FASTA file it will also increase the runtime and memory requirements of the analysis.
  
**More than one of theses reference databases can be used at a time if desired**. To do this you add `--ref` twice in the script (e.g. `--ref smr_v4.3_default_db.fasta --ref smr_v4.3_sensitive_db_rfam_seeds.fasta` ).


### Creating a for loop to run multiple samples at a time
```{bash, eval = FALSE}
#!/bin/bash

#Create arguments
input_dir=$1 #location of the reads
ref_fasta=$2 #desired reference fasta
output_dir_rrna=$3 #desired location for the reads that are rRNA
output_dir_norrna=$4 #desired location for the reads that are NOT rRNA

## Loop through all pairs of reads in the input directory
for pair in $1/*_R1.fastq.gz
        do

        #Extract the sample name from the file name
        sample=$(basename $pair _R1.fastq.gz)

        #Extract Fish ID
        ID=$(basename $pair _paired_R1.fastq.gz)

        ##Echo the sample name it is currently running
        echo "Running SortMeRNA for ${ID}..."

        #Define the paths to the input and output files for this sample
        input1=$1/${sample}_R1.fastq.gz
        input2=$1/${sample}_R2.fastq.gz

        #Run SortMeRNA on this pair of reads
        time sortmerna --threads 16 --ref $2 --reads $input1 --reads $input2 --fastx --aligned $3/${ID} --other $4/${ID} --out2

        #Remove SortMeRNA intermediate files before running again
        rm -r /home/rccuser/sortmerna/run/kvdb
done
```

This script was run as `nohup bash bash_scripts/sortmerna.sh floridae_trimmed ../rRNA_databases_v4.3.4/smr_v4.3_fast_db.fasta floridae_rrna floridae_norrna > sortmerna.log 2>&1 &`

## Doing a k-mer based correction with RCorrector
Rcorrector (RNA-seq error CORRECTOR) is a kmer-based error correction method that is used on RNA-seq data. This program allows for a correction of random sequencing errors in Illumina RNA-seq reads. The downside is you may lose information on things like SNPs and other sequence variants.

### Create a new environment and install Rcorrector in it

```
conda create -n rcorrector
conda activate rcorrector
conda install rcorrector
```

### Creating a for loop to run multiple samples at a time
```{bash, eval = FALSE}
#!/bin/bash

#Create arguments
rcorrector_path=$1 #Path to the run_rcorrector.pl file
input_dir=$2 #Path to the input directory containing the reads
output_dir=$2 #Path to the desired output location

##Loop through all pairs of reads in the directory
for pair in $2/*_R1.fq
        do

        #Extract sample name from the file name
        sample=$(basename $pair _R1.fq)

        #Echo the sample name that is currently running
        echo "Running rcorrector for ${sample} ..."

        #Run rcorrector on this pair of reads
        time perl $1/run_rcorrector.pl -t 16 -1 $2/${sample}_R1.fq -2 $2/${sample}_R2.fq -od $3

done
```

This script was run as `nohup bash bash_scripts/rcor.sh ../../rcorrector floridae_nobio floridae_kmer_corrected/ > rcor.log 2>&1 &`

# De novo transcriptome assembly

```{bash, eval = FALSE}
#!/bin/bash

#Create arguements
samples_file=$1 #File containing sample names and locations
out_dir_name=$2 #Desired name for the output directory

sudo docker run --rm -v`pwd`:`pwd` trinityrnaseq/trinityrnaseq Trinity --seqType fq --max_memory 188G \
        --samples_file $1 \
        --normalize_by_read_set \
        --CPU 16 \
        --output `pwd`/$2
```
